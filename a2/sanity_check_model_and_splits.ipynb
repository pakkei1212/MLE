{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e05548",
   "metadata": {},
   "source": [
    "\n",
    "# Model & Split Sanity Check\n",
    "\n",
    "This notebook helps you **verify the saved model pickle (`.pkl`)** and the **train/test/OOT CSV dumps**.\n",
    "\n",
    "## What it does\n",
    "- Loads the pickled artefact and prints metadata (config, metrics).\n",
    "- Shows pipeline structure and feature columns.\n",
    "- Loads `X_train.csv`, `X_test.csv`, `X_oot.csv` and checks column schemas, basic stats, and leakage risks.\n",
    "- (Optional) Runs the saved pipeline to compute quick AUCs on the CSVs to cross-check with stored metrics.\n",
    "\n",
    "## How to use\n",
    "1. Set the two paths below:\n",
    "   - `MODEL_PKL`: path to your saved model, e.g. `model_bank/credit_model_2024_07_01.pkl`\n",
    "   - `DUMPS_DIR`: directory that holds `X_train.csv`, `X_test.csv`, `X_oot.csv`, e.g. `model_bank/credit_model_2024_07_01/`\n",
    "2. Run all cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d032e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configure paths ---\n",
    "MODEL_PKL = \"scripts/model_bank/credit_model_2024_07_01.pkl\"   # <-- change me\n",
    "DUMPS_DIR = \"scripts/model_bank/credit_model_2024_07_01/\"      # <-- change me\n",
    "\n",
    "import os, json, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7718b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SimpleImputer from version 1.6.1 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.6.1 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.6.1 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(MODEL_PKL, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     artefact \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeys in artefact:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(artefact\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m== CONFIG ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(MODEL_PKL, \"rb\") as f:\n",
    "    artefact = pickle.load(f)\n",
    "\n",
    "print(\"Keys in artefact:\", list(artefact.keys()))\n",
    "print(\"\\n== CONFIG ==\")\n",
    "pprint(artefact[\"config\"])\n",
    "print(\"\\n== TRAIN/TEST/OOT results ==\")\n",
    "pprint(artefact[\"results\"])\n",
    "\n",
    "pipe = artefact[\"pipeline\"]\n",
    "print(\"\\n== Pipeline ==\")\n",
    "print(pipe)\n",
    "\n",
    "print(\"\\n== Feature columns ==\")\n",
    "print(\"Numeric:\", artefact[\"feature_columns\"][\"numeric\"][:10], \"... total\", len(artefact[\"feature_columns\"][\"numeric\"]))\n",
    "print(\"Categorical:\", artefact[\"feature_columns\"][\"categorical\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdd1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_split_csvs(base_dir):\n",
    "    x_train = pd.read_csv(os.path.join(base_dir, \"X_train.csv\"))\n",
    "    y_train = pd.read_csv(os.path.join(base_dir, \"y_train.csv\"))[\"label\"].astype(int)\n",
    "    x_test  = pd.read_csv(os.path.join(base_dir, \"X_test.csv\"))\n",
    "    y_test  = pd.read_csv(os.path.join(base_dir, \"y_test.csv\"))[\"label\"].astype(int)\n",
    "    x_oot   = pd.read_csv(os.path.join(base_dir, \"X_oot.csv\"))\n",
    "    y_oot   = pd.read_csv(os.path.join(base_dir, \"y_oot.csv\"))[\"label\"].astype(int)\n",
    "    return x_train, y_train, x_test, y_test, x_oot, y_oot\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_oot, y_oot = load_split_csvs(DUMPS_DIR)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_train\", X_train.shape, \"y_train\", y_train.shape)\n",
    "print(\"  X_test \", X_test.shape,  \"y_test \", y_test.shape)\n",
    "print(\"  X_oot  \", X_oot.shape,   \"y_oot  \", y_oot.shape)\n",
    "\n",
    "print(\"\\nLabel rates:\")\n",
    "print(\"  train:\", y_train.mean().round(4))\n",
    "print(\"  test :\", y_test.mean().round(4))\n",
    "print(\"  oot  :\", y_oot.mean().round(4))\n",
    "\n",
    "# Quickly check that sets use the same feature columns\n",
    "assert list(X_train.columns) == list(X_test.columns) == list(X_oot.columns), \"Column mismatch across splits!\"\n",
    "print(\"\\nColumn schema consistent across splits ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33123a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show heads\n",
    "display(X_train.head(3))\n",
    "display(X_test.head(3))\n",
    "display(X_oot.head(3))\n",
    "\n",
    "# Basic describe for numeric columns\n",
    "num_cols = [c for c in X_train.columns if np.issubdtype(X_train[c].dtype, np.number)]\n",
    "desc = X_train[num_cols].describe().T\n",
    "display(desc.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If date columns were included in X_*, we can quickly inspect ranges.\n",
    "date_cols = [c for c in X_train.columns if \"date\" in c.lower() or \"snapshot\" in c.lower()]\n",
    "if date_cols:\n",
    "    print(\"Date-like columns detected:\", date_cols)\n",
    "    for dc in date_cols:\n",
    "        try:\n",
    "            tr = pd.to_datetime(X_train[dc], errors='coerce')\n",
    "            te = pd.to_datetime(X_test[dc], errors='coerce')\n",
    "            oo = pd.to_datetime(X_oot[dc], errors='coerce')\n",
    "            print(f\"  {dc}: train [{tr.min()} .. {tr.max()}], test [{te.min()} .. {te.max()}], oot [{oo.min()} .. {oo.max()}]\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Skipping {dc} (parse error):\", e)\n",
    "else:\n",
    "    print(\"No date-like columns detected in X_*.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56769cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quick_eval(pipe, X, y, name):\n",
    "    proba = pipe.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, proba)\n",
    "    gini = 2*auc - 1\n",
    "    print(f\"{name:>6} AUC={auc:.4f} | Gini={gini:.4f}\")\n",
    "    return auc, gini\n",
    "\n",
    "print(\"\\n== Quick AUC cross-checks ==\")\n",
    "auc_tr, g_tr = quick_eval(pipe, X_train, y_train, \"TRAIN\")\n",
    "auc_te, g_te = quick_eval(pipe, X_test, y_test, \" TEST\")\n",
    "auc_oo, g_oo = quick_eval(pipe, X_oot, y_oot, \"  OOT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2bb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If keys are present in the dumps, check for overlap across splits\n",
    "possible_keys = [\"Customer_ID\", \"label_snapshot_date\"]\n",
    "present_keys = [k for k in possible_keys if k in X_train.columns]\n",
    "\n",
    "if present_keys:\n",
    "    print(\"Checking overlaps on keys:\", present_keys)\n",
    "    def kset(df):\n",
    "        return set(map(tuple, df[present_keys].astype(str).itertuples(index=False, name=None)))\n",
    "    inter_train_test = kset(X_train).intersection(kset(X_test))\n",
    "    inter_train_oot  = kset(X_train).intersection(kset(X_oot))\n",
    "    inter_test_oot   = kset(X_test).intersection(kset(X_oot))\n",
    "    print(\"  train ∩ test:\", len(inter_train_test))\n",
    "    print(\"  train ∩ oot :\", len(inter_train_oot))\n",
    "    print(\"  test  ∩ oot :\", len(inter_test_oot))\n",
    "else:\n",
    "    print(\"Key columns not found in X_*; skipping overlap checks.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
