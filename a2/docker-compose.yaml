version: "3.9"

services:
  airflow-init:
    build: .
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=PAqBeGJLJTYFzVkOGHWIYXdLO7XdXz5yTdxAGJe9ezM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - airflow_data:/opt/airflow
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
    entrypoint: >
      /bin/bash -c "
      airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true"
    restart: on-failure
    networks: [airnet]

  airflow-webserver:
    build: .
    depends_on:
      airflow-init:
        condition: service_started
      mlflow:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=PAqBeGJLJTYFzVkOGHWIYXdLO7XdXz5yTdxAGJe9ezM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__WEB_SERVER_HOST=0.0.0.0
      - AIRFLOW__WEBSERVER__WEB_SERVER_PORT=8080
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - airflow_data:/opt/airflow
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
    ports:
      - "8080:8080"
    command: webserver
    restart: unless-stopped
    networks: [airnet]

  airflow-scheduler:
    build: .
    depends_on:
      airflow-init:
        condition: service_started
      mlflow:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=PAqBeGJLJTYFzVkOGHWIYXdLO7XdXz5yTdxAGJe9ezM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - airflow_data:/opt/airflow
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
    command: scheduler
    restart: unless-stopped
    networks: [airnet]

  mlflow:
    image: python:3.10-slim
    container_name: mlflow
    working_dir: /srv
    environment:
      GUNICORN_CMD_ARGS: "--bind 0.0.0.0:5000 --workers 3 --timeout 120"
    command: >
      bash -lc "
      pip install --no-cache-dir mlflow==2.16.0 &&
      mlflow server
        --host 0.0.0.0
        --port 5000
        --backend-store-uri sqlite:////srv/mlflow.db
        --default-artifact-root /srv/mlruns
        --serve-artifacts
      "
    ports:
      - "5000:5000"
    volumes:
      - ./mlflow_srv:/srv
    restart: unless-stopped
    networks: [airnet]
    healthcheck:
      test: ["CMD-SHELL", "python - <<'PY'\nimport urllib.request,sys\nsys.exit(0 if urllib.request.urlopen('http://localhost:5000', timeout=2).status==200 else 1)\nPY"]
      interval: 10s
      timeout: 3s
      retries: 30

  lab:
    image: jupyter/pyspark-notebook:latest
    container_name: mle-a2-jupyter
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    ports:
      - "8891:8891"
    volumes:
      - .:/app
    working_dir: /app
    command:
      - start-notebook.sh
      - --ServerApp.ip=0.0.0.0
      - --ServerApp.port=8891
      - --ServerApp.root_dir=/app
      - --ServerApp.token=
      - --ServerApp.password=
      - --ServerApp.disable_check_xsrf=True
    networks: [airnet]

volumes:
  airflow_data:

networks:
  airnet:
    driver: bridge
